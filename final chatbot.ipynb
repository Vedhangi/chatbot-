{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7155895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9c86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []\n",
    "responses = []\n",
    "\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063e1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea1633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2159c786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0632 - loss: 3.6377\n",
      "Epoch 2/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0482 - loss: 3.6334     \n",
      "Epoch 3/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0378 - loss: 3.6296     \n",
      "Epoch 4/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0494 - loss: 3.6259 \n",
      "Epoch 5/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0627 - loss: 3.6213 \n",
      "Epoch 6/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0617 - loss: 3.6126 \n",
      "Epoch 7/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0694 - loss: 3.5953 \n",
      "Epoch 8/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0598 - loss: 3.5875 \n",
      "Epoch 9/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0529 - loss: 3.5686 \n",
      "Epoch 10/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0516 - loss: 3.5573 \n",
      "Epoch 11/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0859 - loss: 3.5216 \n",
      "Epoch 12/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0619 - loss: 3.4998 \n",
      "Epoch 13/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0599 - loss: 3.5068 \n",
      "Epoch 14/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0603 - loss: 3.4761 \n",
      "Epoch 15/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0574 - loss: 3.4505     \n",
      "Epoch 16/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0520 - loss: 3.4549     \n",
      "Epoch 17/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0466 - loss: 3.4489 \n",
      "Epoch 18/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0403 - loss: 3.4209 \n",
      "Epoch 19/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0504 - loss: 3.4068 \n",
      "Epoch 20/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0977 - loss: 3.3916 \n",
      "Epoch 21/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0812 - loss: 3.3904 \n",
      "Epoch 22/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0717 - loss: 3.3400 \n",
      "Epoch 23/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1494 - loss: 3.3174 \n",
      "Epoch 24/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0648 - loss: 3.3153     \n",
      "Epoch 25/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1285 - loss: 3.2755 \n",
      "Epoch 26/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1445 - loss: 3.2491 \n",
      "Epoch 27/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1102 - loss: 3.1965 \n",
      "Epoch 28/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1399 - loss: 3.1724 \n",
      "Epoch 29/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1388 - loss: 3.1546 \n",
      "Epoch 30/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1475 - loss: 3.0828 \n",
      "Epoch 31/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1684 - loss: 3.1072 \n",
      "Epoch 32/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1520 - loss: 3.0242 \n",
      "Epoch 33/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1888 - loss: 2.9597 \n",
      "Epoch 34/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1862 - loss: 2.9705 \n",
      "Epoch 35/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1780 - loss: 2.9443 \n",
      "Epoch 36/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1926 - loss: 2.9836 \n",
      "Epoch 37/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1724 - loss: 2.9495 \n",
      "Epoch 38/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2028 - loss: 2.8475 \n",
      "Epoch 39/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1882 - loss: 2.8274 \n",
      "Epoch 40/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1972 - loss: 2.8693 \n",
      "Epoch 41/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2002 - loss: 2.8180 \n",
      "Epoch 42/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2024 - loss: 2.7775 \n",
      "Epoch 43/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2290 - loss: 2.7831 \n",
      "Epoch 44/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2190 - loss: 2.7189 \n",
      "Epoch 45/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2149 - loss: 2.6808 \n",
      "Epoch 46/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2188 - loss: 2.6710 \n",
      "Epoch 47/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2609 - loss: 2.5829 \n",
      "Epoch 48/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2672 - loss: 2.5730 \n",
      "Epoch 49/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2488 - loss: 2.6181 \n",
      "Epoch 50/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2223 - loss: 2.5664 \n",
      "Epoch 51/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2493 - loss: 2.5461 \n",
      "Epoch 52/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2908 - loss: 2.4387 \n",
      "Epoch 53/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2620 - loss: 2.4357 \n",
      "Epoch 54/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2768 - loss: 2.4267 \n",
      "Epoch 55/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3045 - loss: 2.4006 \n",
      "Epoch 56/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2928 - loss: 2.3649 \n",
      "Epoch 57/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3117 - loss: 2.2935 \n",
      "Epoch 58/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2964 - loss: 2.3158 \n",
      "Epoch 59/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3681 - loss: 2.2336 \n",
      "Epoch 60/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3699 - loss: 2.2084 \n",
      "Epoch 61/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3723 - loss: 2.1517 \n",
      "Epoch 62/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3671 - loss: 2.1954 \n",
      "Epoch 63/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3610 - loss: 2.1140 \n",
      "Epoch 64/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4029 - loss: 2.0776 \n",
      "Epoch 65/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3631 - loss: 2.1229 \n",
      "Epoch 66/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3819 - loss: 2.0482 \n",
      "Epoch 67/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4196 - loss: 2.0159 \n",
      "Epoch 68/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3909 - loss: 2.0335 \n",
      "Epoch 69/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4042 - loss: 2.0032 \n",
      "Epoch 70/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4049 - loss: 1.9419 \n",
      "Epoch 71/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4383 - loss: 1.9848 \n",
      "Epoch 72/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4224 - loss: 1.8864 \n",
      "Epoch 73/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4357 - loss: 1.8571 \n",
      "Epoch 74/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4295 - loss: 1.8849 \n",
      "Epoch 75/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4981 - loss: 1.8100 \n",
      "Epoch 76/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4717 - loss: 1.7938 \n",
      "Epoch 77/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4896 - loss: 1.7188 \n",
      "Epoch 78/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4363 - loss: 1.8092 \n",
      "Epoch 79/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4655 - loss: 1.8375 \n",
      "Epoch 80/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4662 - loss: 1.7602 \n",
      "Epoch 81/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4972 - loss: 1.7590 \n",
      "Epoch 82/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5157 - loss: 1.6988 \n",
      "Epoch 83/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4974 - loss: 1.7164 \n",
      "Epoch 84/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5067 - loss: 1.6595 \n",
      "Epoch 85/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4830 - loss: 1.6352 \n",
      "Epoch 86/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5210 - loss: 1.5786 \n",
      "Epoch 87/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5282 - loss: 1.5602 \n",
      "Epoch 88/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5334 - loss: 1.5449 \n",
      "Epoch 89/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5139 - loss: 1.5372 \n",
      "Epoch 90/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5202 - loss: 1.5710 \n",
      "Epoch 91/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5460 - loss: 1.5078 \n",
      "Epoch 92/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5598 - loss: 1.4861 \n",
      "Epoch 93/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5532 - loss: 1.4454 \n",
      "Epoch 94/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 1.4079 \n",
      "Epoch 95/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 1.4199 \n",
      "Epoch 96/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6110 - loss: 1.4249 \n",
      "Epoch 97/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 1.4251 \n",
      "Epoch 98/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5817 - loss: 1.4037 \n",
      "Epoch 99/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6432 - loss: 1.3848 \n",
      "Epoch 100/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6180 - loss: 1.3604 \n",
      "Epoch 101/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6507 - loss: 1.3214 \n",
      "Epoch 102/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6427 - loss: 1.3058 \n",
      "Epoch 103/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5948 - loss: 1.3459 \n",
      "Epoch 104/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6521 - loss: 1.3272 \n",
      "Epoch 105/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6492 - loss: 1.2952 \n",
      "Epoch 106/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 1.3123 \n",
      "Epoch 107/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6819 - loss: 1.2236 \n",
      "Epoch 108/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6672 - loss: 1.2542 \n",
      "Epoch 109/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6852 - loss: 1.2117 \n",
      "Epoch 110/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7031 - loss: 1.2261 \n",
      "Epoch 111/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 1.2458 \n",
      "Epoch 112/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6626 - loss: 1.2627 \n",
      "Epoch 113/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 1.1925 \n",
      "Epoch 114/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7124 - loss: 1.2315 \n",
      "Epoch 115/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7205 - loss: 1.1449 \n",
      "Epoch 116/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 1.0970 \n",
      "Epoch 117/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7640 - loss: 1.1509 \n",
      "Epoch 118/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 1.0953 \n",
      "Epoch 119/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 1.1148 \n",
      "Epoch 120/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 1.0568 \n",
      "Epoch 121/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7487 - loss: 1.1059 \n",
      "Epoch 122/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 1.0425 \n",
      "Epoch 123/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.9887 \n",
      "Epoch 124/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 1.0950 \n",
      "Epoch 125/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 1.0678 \n",
      "Epoch 126/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 1.0385 \n",
      "Epoch 127/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 1.0529 \n",
      "Epoch 128/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 1.0133 \n",
      "Epoch 129/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.9739 \n",
      "Epoch 130/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.9640 \n",
      "Epoch 131/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7794 - loss: 0.9443 \n",
      "Epoch 132/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7751 - loss: 0.9674 \n",
      "Epoch 133/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 1.0039 \n",
      "Epoch 134/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.9469 \n",
      "Epoch 135/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.9176 \n",
      "Epoch 136/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.9668 \n",
      "Epoch 137/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.8852 \n",
      "Epoch 138/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.9205 \n",
      "Epoch 139/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.8769 \n",
      "Epoch 140/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.8895 \n",
      "Epoch 141/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.9290 \n",
      "Epoch 142/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.8530 \n",
      "Epoch 143/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8370 - loss: 0.8600 \n",
      "Epoch 144/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8459 - loss: 0.8454 \n",
      "Epoch 145/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8428 - loss: 0.8218 \n",
      "Epoch 146/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8382 - loss: 0.8670 \n",
      "Epoch 147/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.8733 \n",
      "Epoch 148/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.8082 \n",
      "Epoch 149/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.8219 \n",
      "Epoch 150/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.8345 \n",
      "Epoch 151/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8479 - loss: 0.8502 \n",
      "Epoch 152/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.7785 \n",
      "Epoch 153/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8554 - loss: 0.7896 \n",
      "Epoch 154/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.7687 \n",
      "Epoch 155/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.7567 \n",
      "Epoch 156/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.7865 \n",
      "Epoch 157/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.7322 \n",
      "Epoch 158/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.7665 \n",
      "Epoch 159/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.7642 \n",
      "Epoch 160/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.7034 \n",
      "Epoch 161/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.7399  \n",
      "Epoch 162/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.7185 \n",
      "Epoch 163/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.6866 \n",
      "Epoch 164/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.7132 \n",
      "Epoch 165/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8943 - loss: 0.6529 \n",
      "Epoch 166/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8635 - loss: 0.6786 \n",
      "Epoch 167/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.7168 \n",
      "Epoch 168/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.6625 \n",
      "Epoch 169/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.6441 \n",
      "Epoch 170/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.6682 \n",
      "Epoch 171/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.6545 \n",
      "Epoch 172/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.6678 \n",
      "Epoch 173/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.6370 \n",
      "Epoch 174/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.6551 \n",
      "Epoch 175/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.5773 \n",
      "Epoch 176/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.6154 \n",
      "Epoch 177/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.6719 \n",
      "Epoch 178/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.6596 \n",
      "Epoch 179/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 0.6121 \n",
      "Epoch 180/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.5946 \n",
      "Epoch 181/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.6194 \n",
      "Epoch 182/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.5778 \n",
      "Epoch 183/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.5761 \n",
      "Epoch 184/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.5722 \n",
      "Epoch 185/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.5444 \n",
      "Epoch 186/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.6015 \n",
      "Epoch 187/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.5260 \n",
      "Epoch 188/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.5681 \n",
      "Epoch 189/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.5446 \n",
      "Epoch 190/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.5114 \n",
      "Epoch 191/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.5510 \n",
      "Epoch 192/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.5410 \n",
      "Epoch 193/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.5585 \n",
      "Epoch 194/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.5694 \n",
      "Epoch 195/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.5314 \n",
      "Epoch 196/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.4854 \n",
      "Epoch 197/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9214 - loss: 0.4846 \n",
      "Epoch 198/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.5187 \n",
      "Epoch 199/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.5000 \n",
      "Epoch 200/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.5092 \n",
      "Epoch 201/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9230 - loss: 0.4698 \n",
      "Epoch 202/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.4986 \n",
      "Epoch 203/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.4582 \n",
      "Epoch 204/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.4699 \n",
      "Epoch 205/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.5148 \n",
      "Epoch 206/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.4369 \n",
      "Epoch 207/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.4581 \n",
      "Epoch 208/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.4505 \n",
      "Epoch 209/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.4433 \n",
      "Epoch 210/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.4617 \n",
      "Epoch 211/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.4939 \n",
      "Epoch 212/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.4799 \n",
      "Epoch 213/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.4319 \n",
      "Epoch 214/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.4375 \n",
      "Epoch 215/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.4359 \n",
      "Epoch 216/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.4695 \n",
      "Epoch 217/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.4228 \n",
      "Epoch 218/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9280 - loss: 0.4272 \n",
      "Epoch 219/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.4139 \n",
      "Epoch 220/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.4076 \n",
      "Epoch 221/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.3811 \n",
      "Epoch 222/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 0.4131 \n",
      "Epoch 223/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.3536 \n",
      "Epoch 224/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.4484 \n",
      "Epoch 225/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.3659 \n",
      "Epoch 226/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.3989 \n",
      "Epoch 227/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.3577 \n",
      "Epoch 228/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.4084 \n",
      "Epoch 229/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.3640 \n",
      "Epoch 230/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.4073 \n",
      "Epoch 231/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 0.3750 \n",
      "Epoch 232/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.3753 \n",
      "Epoch 233/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.3465 \n",
      "Epoch 234/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.3470 \n",
      "Epoch 235/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.3645 \n",
      "Epoch 236/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.3669 \n",
      "Epoch 237/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.3586 \n",
      "Epoch 238/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.3353 \n",
      "Epoch 239/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.3546 \n",
      "Epoch 240/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.3494 \n",
      "Epoch 241/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.3185 \n",
      "Epoch 242/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.3161 \n",
      "Epoch 243/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.3300 \n",
      "Epoch 244/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.3102 \n",
      "Epoch 245/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9344 - loss: 0.3242 \n",
      "Epoch 246/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.2909 \n",
      "Epoch 247/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9355 - loss: 0.3339 \n",
      "Epoch 248/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.2976 \n",
      "Epoch 249/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.2998 \n",
      "Epoch 250/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.2841 \n",
      "Epoch 251/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.3392 \n",
      "Epoch 252/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9322 - loss: 0.3081 \n",
      "Epoch 253/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.2966 \n",
      "Epoch 254/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.2904 \n",
      "Epoch 255/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9453 - loss: 0.2890 \n",
      "Epoch 256/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.2978 \n",
      "Epoch 257/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.3364 \n",
      "Epoch 258/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.2615 \n",
      "Epoch 259/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.3032 \n",
      "Epoch 260/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.2666 \n",
      "Epoch 261/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.2775 \n",
      "Epoch 262/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.2672 \n",
      "Epoch 263/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.2568 \n",
      "Epoch 264/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.2653 \n",
      "Epoch 265/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.2764 \n",
      "Epoch 266/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.2835 \n",
      "Epoch 267/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.2554 \n",
      "Epoch 268/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9371 - loss: 0.2719 \n",
      "Epoch 269/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9552 - loss: 0.2560 \n",
      "Epoch 270/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.2580 \n",
      "Epoch 271/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.2567 \n",
      "Epoch 272/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.2535 \n",
      "Epoch 273/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.2310 \n",
      "Epoch 274/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.2464 \n",
      "Epoch 275/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.2326 \n",
      "Epoch 276/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.2543 \n",
      "Epoch 277/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.2672 \n",
      "Epoch 278/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.2442 \n",
      "Epoch 279/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.2325 \n",
      "Epoch 280/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.2235 \n",
      "Epoch 281/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.2631 \n",
      "Epoch 282/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.2431 \n",
      "Epoch 283/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.2376 \n",
      "Epoch 284/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9379 - loss: 0.2615 \n",
      "Epoch 285/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.2394 \n",
      "Epoch 286/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.2493 \n",
      "Epoch 287/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.2143 \n",
      "Epoch 288/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.2164 \n",
      "Epoch 289/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.2028 \n",
      "Epoch 290/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1970 \n",
      "Epoch 291/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.1889 \n",
      "Epoch 292/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.2242 \n",
      "Epoch 293/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.2314  \n",
      "Epoch 294/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.2128 \n",
      "Epoch 295/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.2222 \n",
      "Epoch 296/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9662 - loss: 0.1995 \n",
      "Epoch 297/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9716 - loss: 0.1932 \n",
      "Epoch 298/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.2027 \n",
      "Epoch 299/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.2053 \n",
      "Epoch 300/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.2062 \n",
      "Epoch 301/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.2359 \n",
      "Epoch 302/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.1901 \n",
      "Epoch 303/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.1828 \n",
      "Epoch 304/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.2033 \n",
      "Epoch 305/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.1830 \n",
      "Epoch 306/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.1770 \n",
      "Epoch 307/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.2070 \n",
      "Epoch 308/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.1923 \n",
      "Epoch 309/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.1734 \n",
      "Epoch 310/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1919 \n",
      "Epoch 311/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.1762 \n",
      "Epoch 312/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.1785 \n",
      "Epoch 313/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.1760 \n",
      "Epoch 314/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1809 \n",
      "Epoch 315/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.1681 \n",
      "Epoch 316/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.1724 \n",
      "Epoch 317/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9539 - loss: 0.1888 \n",
      "Epoch 318/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9618 - loss: 0.1786 \n",
      "Epoch 319/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.1620 \n",
      "Epoch 320/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1653 \n",
      "Epoch 321/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9726 - loss: 0.1725 \n",
      "Epoch 322/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.1540  \n",
      "Epoch 323/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.1547 \n",
      "Epoch 324/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.1549 \n",
      "Epoch 325/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.1604 \n",
      "Epoch 326/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.1808 \n",
      "Epoch 327/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.1500 \n",
      "Epoch 328/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1831 \n",
      "Epoch 329/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.1708 \n",
      "Epoch 330/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.1721 \n",
      "Epoch 331/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.1499 \n",
      "Epoch 332/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.1538 \n",
      "Epoch 333/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1519 \n",
      "Epoch 334/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.1448 \n",
      "Epoch 335/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.1545 \n",
      "Epoch 336/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.1547 \n",
      "Epoch 337/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.1470 \n",
      "Epoch 338/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.1556 \n",
      "Epoch 339/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9714 - loss: 0.1444 \n",
      "Epoch 340/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.1477 \n",
      "Epoch 341/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.1382 \n",
      "Epoch 342/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.1449 \n",
      "Epoch 343/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1398 \n",
      "Epoch 344/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.1365 \n",
      "Epoch 345/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1560 \n",
      "Epoch 346/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1539 \n",
      "Epoch 347/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.1246 \n",
      "Epoch 348/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1448 \n",
      "Epoch 349/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.1461 \n",
      "Epoch 350/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1508 \n",
      "Epoch 351/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.1274 \n",
      "Epoch 352/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1504 \n",
      "Epoch 353/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.1376 \n",
      "Epoch 354/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.1231 \n",
      "Epoch 355/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.1202 \n",
      "Epoch 356/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1192 \n",
      "Epoch 357/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.1232 \n",
      "Epoch 358/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.1231 \n",
      "Epoch 359/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.1072 \n",
      "Epoch 360/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.1209 \n",
      "Epoch 361/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.1381 \n",
      "Epoch 362/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.1301 \n",
      "Epoch 363/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.1119 \n",
      "Epoch 364/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.1128 \n",
      "Epoch 365/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.1190 \n",
      "Epoch 366/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1230 \n",
      "Epoch 367/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.1296 \n",
      "Epoch 368/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.1242 \n",
      "Epoch 369/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.1197 \n",
      "Epoch 370/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.1097 \n",
      "Epoch 371/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.1346 \n",
      "Epoch 372/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.1148 \n",
      "Epoch 373/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.1113 \n",
      "Epoch 374/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.1285 \n",
      "Epoch 375/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.1063 \n",
      "Epoch 376/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.1127 \n",
      "Epoch 377/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.1116 \n",
      "Epoch 378/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.1258 \n",
      "Epoch 379/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.1100 \n",
      "Epoch 380/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.1048 \n",
      "Epoch 381/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.1016 \n",
      "Epoch 382/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.1224 \n",
      "Epoch 383/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0950 \n",
      "Epoch 384/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.1158 \n",
      "Epoch 385/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0983 \n",
      "Epoch 386/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0932 \n",
      "Epoch 387/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.1007 \n",
      "Epoch 388/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0918 \n",
      "Epoch 389/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.1062 \n",
      "Epoch 390/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.1050 \n",
      "Epoch 391/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.1062 \n",
      "Epoch 392/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.1113 \n",
      "Epoch 393/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0892 \n",
      "Epoch 394/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.1133 \n",
      "Epoch 395/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0987 \n",
      "Epoch 396/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0987 \n",
      "Epoch 397/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.1003 \n",
      "Epoch 398/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.1119 \n",
      "Epoch 399/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0941 \n",
      "Epoch 400/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0835 \n",
      "Epoch 401/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0928 \n",
      "Epoch 402/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0955 \n",
      "Epoch 403/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.1001 \n",
      "Epoch 404/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0905 \n",
      "Epoch 405/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0890 \n",
      "Epoch 406/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0951 \n",
      "Epoch 407/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0852 \n",
      "Epoch 408/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0803 \n",
      "Epoch 409/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0906 \n",
      "Epoch 410/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0892 \n",
      "Epoch 411/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0932 \n",
      "Epoch 412/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0834 \n",
      "Epoch 413/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0802 \n",
      "Epoch 414/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0713 \n",
      "Epoch 415/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0895 \n",
      "Epoch 416/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0911 \n",
      "Epoch 417/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0908 \n",
      "Epoch 418/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0880 \n",
      "Epoch 419/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0939 \n",
      "Epoch 420/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0763 \n",
      "Epoch 421/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0804 \n",
      "Epoch 422/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0690 \n",
      "Epoch 423/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0789 \n",
      "Epoch 424/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0893 \n",
      "Epoch 425/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0673 \n",
      "Epoch 426/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0715 \n",
      "Epoch 427/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0704 \n",
      "Epoch 428/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0741 \n",
      "Epoch 429/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0661 \n",
      "Epoch 430/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0764 \n",
      "Epoch 431/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0576 \n",
      "Epoch 432/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0718 \n",
      "Epoch 433/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0645 \n",
      "Epoch 434/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0713  \n",
      "Epoch 435/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0608 \n",
      "Epoch 436/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0779 \n",
      "Epoch 437/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0672 \n",
      "Epoch 438/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0704 \n",
      "Epoch 439/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0672 \n",
      "Epoch 440/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0735 \n",
      "Epoch 441/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0555 \n",
      "Epoch 442/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0723 \n",
      "Epoch 443/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0761 \n",
      "Epoch 444/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0643 \n",
      "Epoch 445/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0597 \n",
      "Epoch 446/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0624 \n",
      "Epoch 447/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0651 \n",
      "Epoch 448/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0611 \n",
      "Epoch 449/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0665 \n",
      "Epoch 450/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0702 \n",
      "Epoch 451/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0534 \n",
      "Epoch 452/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0513 \n",
      "Epoch 453/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0578 \n",
      "Epoch 454/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0642 \n",
      "Epoch 455/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0711 \n",
      "Epoch 456/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0590 \n",
      "Epoch 457/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0490 \n",
      "Epoch 458/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0559 \n",
      "Epoch 459/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0666 \n",
      "Epoch 460/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0549 \n",
      "Epoch 461/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0689 \n",
      "Epoch 462/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0632 \n",
      "Epoch 463/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0462 \n",
      "Epoch 464/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0585 \n",
      "Epoch 465/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0626 \n",
      "Epoch 466/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0576 \n",
      "Epoch 467/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0663 \n",
      "Epoch 468/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0552 \n",
      "Epoch 469/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0633 \n",
      "Epoch 470/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0584 \n",
      "Epoch 471/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0480 \n",
      "Epoch 472/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0545 \n",
      "Epoch 473/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0648 \n",
      "Epoch 474/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0518 \n",
      "Epoch 475/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0519 \n",
      "Epoch 476/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0634 \n",
      "Epoch 477/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0492 \n",
      "Epoch 478/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0467 \n",
      "Epoch 479/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0505 \n",
      "Epoch 480/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0463 \n",
      "Epoch 481/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0638 \n",
      "Epoch 482/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0650 \n",
      "Epoch 483/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0500 \n",
      "Epoch 484/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0457 \n",
      "Epoch 485/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0437 \n",
      "Epoch 486/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0493 \n",
      "Epoch 487/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0628 \n",
      "Epoch 488/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0479 \n",
      "Epoch 489/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0527 \n",
      "Epoch 490/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0438 \n",
      "Epoch 491/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0490 \n",
      "Epoch 492/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0462 \n",
      "Epoch 493/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0506 \n",
      "Epoch 494/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0601 \n",
      "Epoch 495/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0396 \n",
      "Epoch 496/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0438 \n",
      "Epoch 497/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0477 \n",
      "Epoch 498/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0450 \n",
      "Epoch 499/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0461 \n",
      "Epoch 500/500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0458 \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# Define your model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))  # Remove input_length here\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Calculate the actual number of classes in your dataset\n",
    "num_classes = len(set(training_labels))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train your model\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2a8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model with a .h5 extension\n",
    "model.save(\"chat_model.h5\")\n",
    "\n",
    "# Save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# Save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49e28e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: quit\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2165955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 161ms/st ━━━━━━━━━━━━━━━━━━━━ 0s 174ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load intents and models\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Load trained model\n",
    "model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "# Load tokenizer object\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load label encoder object\n",
    "with open('label_encoder.pickle', 'rb') as enc:\n",
    "    lbl_encoder = pickle.load(enc)\n",
    "\n",
    "# Parameters\n",
    "max_len = 20\n",
    "\n",
    "\n",
    "test_sentences = [\"How are you?\", \"What time is it?\", \"Where are you located?\"]\n",
    "test_labels = [\"greeting\", \"time\", \"location\"]\n",
    "\n",
    "# Tokenize and pad test sentences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, truncating='post', maxlen=max_len)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(padded_test_sequences)\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "predicted_labels = lbl_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# Get the list of unique labels\n",
    "labels = np.unique(np.concatenate((test_labels, predicted_labels)))\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels, labels=labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3b51d79",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Invalid \\escape: line 308 column 77 (char 7715)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load intents and models\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintents.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenizer.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Invalid \\escape: line 308 column 77 (char 7715)"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from tkinter import messagebox\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Load intents and models\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "model = keras.models.load_model('chat_model.h5')\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "with open('label_encoder.pickle', 'rb') as enc:\n",
    "    lbl_encoder = pickle.load(enc)\n",
    "\n",
    "# Parameters\n",
    "max_len = 20\n",
    "\n",
    "# Function to get response from the chatbot\n",
    "def get_response():\n",
    "    user_input = user_input_text.get(\"1.0\",'end-1c')\n",
    "    user_input_text.delete(\"1.0\",'end')\n",
    "\n",
    "    if user_input.lower() == \"quit\":\n",
    "        root.destroy()\n",
    "        return\n",
    "\n",
    "    result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([user_input]),\n",
    "                                         truncating='post', maxlen=max_len))\n",
    "    tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "    for i in data['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            response = np.random.choice(i['responses'])\n",
    "            chat_history_text.configure(state='normal')\n",
    "            chat_history_text.insert(tk.END, \"You: \" + user_input + \"\\n\", \"user\")\n",
    "            chat_history_text.insert(tk.END, \"ChatBot: \" + response + \"\\n\", \"bot\")\n",
    "            chat_history_text.configure(state='disabled')\n",
    "            chat_history_text.yview(tk.END)\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Simple Chatbot\")\n",
    "\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(pady=10)\n",
    "\n",
    "chat_history_text = scrolledtext.ScrolledText(frame, height=20, width=50)\n",
    "chat_history_text.grid(row=0, column=0, padx=5, pady=5, columnspan=2)\n",
    "chat_history_text.tag_config(\"user\", foreground=\"blue\")\n",
    "chat_history_text.tag_config(\"bot\", foreground=\"green\")\n",
    "chat_history_text.configure(state='disabled')\n",
    "\n",
    "user_input_text = tk.Text(frame, height=3, width=50)\n",
    "user_input_text.grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "send_button = tk.Button(frame, text=\"Send\", command=get_response)\n",
    "send_button.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03437371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Extract test sentences and labels from the first 1000 examples of the dataset\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     33\u001b[0m     test_sentences\u001b[38;5;241m.\u001b[39mappend(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     34\u001b[0m     test_labels\u001b[38;5;241m.\u001b[39mappend(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load intents and models\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Load trained model\n",
    "model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "# Load tokenizer object\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load label encoder object\n",
    "with open('label_encoder.pickle', 'rb') as enc:\n",
    "    lbl_encoder = pickle.load(enc)\n",
    "\n",
    "# Parameters\n",
    "max_len = 20\n",
    "\n",
    "# Initialize an empty list to store test sentences and labels\n",
    "test_sentences = []\n",
    "test_labels = []\n",
    "\n",
    "# Extract test sentences and labels from the first 1000 examples of the dataset\n",
    "for example in data[:1000]:\n",
    "    test_sentences.append(example['text'])\n",
    "    test_labels.append(example['label'])\n",
    "\n",
    "# Tokenize and pad test sentences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "padded_test_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, truncating='post', maxlen=max_len)\n",
    "\n",
    "# Get the list of unique labels\n",
    "labels = lbl_encoder.classes_\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = model.predict(padded_test_sequences)\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, labels[predicted_labels], labels=labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3799cbe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder Classes: ['admission' 'canteen' 'college intake' 'committee' 'computerhod' 'course'\n",
      " 'creator' 'document' 'event' 'extchod' 'facilities' 'fees' 'floors'\n",
      " 'goodbye' 'greeting' 'hod' 'hostel' 'hours' 'infrastructure' 'ithod'\n",
      " 'library' 'location' 'menu' 'name' 'number' 'placement' 'principal'\n",
      " 'ragging' 'random' 'salutaion' 'scholarship' 'sem' 'sports' 'swear'\n",
      " 'syllabus' 'task' 'uniform' 'vacation']\n",
      "New labels found: {'CourtesyGreetingResponse', 'Shutup', 'PodBayDoor', 'WhoAmI', 'Greeting', 'CourtesyGoodBye', 'RealNameQuery', 'NameQuery', 'Thanks', 'CurrentHumanQuery', 'NotTalking2U', 'SelfAware', 'TimeQuery', 'GoodBye', 'Gossip', 'UnderstandQuery', 'PodBayDoorResponse', 'CourtesyGreeting', 'GreetingResponse', 'Jokes', 'Swearing', 'Clever'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'Greeting'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Greeting'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m new_padded_sequences \u001b[38;5;241m=\u001b[39m pad_sequences(new_sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Encode new training labels using the existing label encoder\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m new_encoded_labels \u001b[38;5;241m=\u001b[39m \u001b[43mlbl_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_training_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Define model architecture\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     38\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mEmbedding(vocab_size, embedding_dim, input_length\u001b[38;5;241m=\u001b[39mmax_len),\n\u001b[0;32m     39\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling1D(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m ])\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\vedhangi_anaconda\\lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'Greeting'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load new data\n",
    "with open(\"new_intents.json\") as file:\n",
    "    new_data = json.load(file)\n",
    "# Check Label Encoder Classes\n",
    "print(\"Label Encoder Classes:\", lbl_encoder.classes_)\n",
    "\n",
    "# Preprocess data\n",
    "new_training_sentences = []\n",
    "new_training_labels = []\n",
    "for intent in new_data['intents']:\n",
    "    for pattern in intent['text']:\n",
    "        new_training_sentences.append(pattern)\n",
    "        new_training_labels.append(intent['intent'])\n",
    "\n",
    "# Check for any new labels in the training data\n",
    "new_labels_set = set(new_training_labels)\n",
    "existing_labels_set = set(lbl_encoder.classes_)\n",
    "new_labels = new_labels_set - existing_labels_set\n",
    "if new_labels:\n",
    "    print(\"New labels found:\", new_labels)\n",
    "\n",
    "# Tokenize and pad new training sentences\n",
    "new_sequences = tokenizer.texts_to_sequences(new_training_sentences)\n",
    "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Encode new training labels using the existing label encoder\n",
    "new_encoded_labels = lbl_encoder.transform(new_training_labels)\n",
    "\n",
    "# Define model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "epochs = 10\n",
    "history = model.fit(new_padded_sequences, new_encoded_labels, epochs=epochs)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(new_padded_sequences, new_encoded_labels)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Save model and preprocessing objects\n",
    "model.save(\"retrained_chat_model.h5\")\n",
    "with open('retrained_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('retrained_label_encoder.pickle', 'wb') as enc_file:\n",
    "    pickle.dump(lbl_encoder, enc_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acec8f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (2.16.1)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (22.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: namex in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vedha\\anaconda3\\vedhangi_anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f596f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
